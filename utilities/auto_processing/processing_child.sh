#!/bin/bash -e
#Use lock files to automatically extend processing to n jobs
#Each child gets an ID, it's own log and error files, and also keeps log
#and error files for each series/dump it processes
VERSION="2.2.1"

umask 002

print_usage(){
    cat<<EOF
This script should only be invoked by processing_master. It launches a child 
process that works through all the existing scripts in a directory.  
It requires 2 arguments: child ID and the directory to work in.
An optional third argument can be an email address to notify in case of errors
or when the job is finished.
EOF
exit $ARGERROR
}

#we should get 2 arguments: our ID and the processing directory
if [ $# -lt 2 ] || [ $# -gt 3 ] ; then print_usage ; fi
ID=$1
WORKDIR=$2
EMAILADDY=""
if [ $# -gt 2 ] ; then
    EMAILADDY=$3
fi

#see if the mail program is useable
MAIL=`which mail`
if [ -z "$MAIL" ] ; then
    EMAILADDY=""
fi

#move into workdir so that sub-scripts can use relative paths
set +e
while [ ! -e $WORKDIR ] ; do 
    cd $WORKDIR ; sleep 1
done
cd $WORKDIR
set -e

#paths.sh should have been placed by parent; contains working info
if [ ! -f jobsetup.sh ] ; then
    echo "ERROR: Unable to locate jobsetup.sh file in $WORKDIR. Aborting" >&2
    exit $CONFIGERROR
fi

source jobsetup.sh

echo "$(tstamp): processing_child version $VERSION with id $ID on host `hostname` starting in $WORKDIR"

#check the size limit in /tmp dir and alert if there is no availabe space
## Show available space in TMP
echo " ############# Checking available space in tmp area: ##############"
df -h $SCRATCHDIR
FREESP=$(df -m $SCRATCHDIR | tail -n 1 | tr -s ' ' | cut -d ' ' -f 4)
echo "         >> ${FREESP} MB available in host `hostname` "
echo " "

## Throw error if space is less than 2000 MB
if [ "${FREESP}" -le "2000" ] ; then
    echo ">>>> ERROR all Exit status 8080     |   FAIL all $FPULSE $LPULSE  `date`"
    echo "     Not enough space in tmp area, only ${FREESP} MB left."
    echo "     HOST:  `hostname`"
    echo "     TMP_DIR:  $SCRATCHDIR"
    exit 8080
fi


if [[ "$BATROOT_TEMPLATENAMES" == "" ]] ; then
    echo "${BATROOT_TEMPLATENAMES}"
    echo "Unsetting BATROOT TEMPLATENAMES (it appears to be defined as empty string)"
    unset BATROOT_TEMPLATENAMES
fi
# copy the pulse libraries [AJA]
if [[ -n $BATROOT_TEMPLATENAMES ]]; then 
    echo "PULSE SIM templates:"$BATROOT_TEMPLATENAMES
else
    echo "DATA PROCESSING"
fi

# sleeping for a little while (less than 6 seconds) to avoid race conditions at the beginning
SLTM=$(bc -l <<< "scale=4 ; 4*${RANDOM}/32767 +2 ")
echo "Sleeping for $SLTM (to avoid race condition at the beginning)"
sleep $SLTM
echo "Starting stage iteration" 

#allow up to 9 processing stages
for stage in {1..9} ; do
    stagedir="stage${stage}"
    #make sure there is a stage for this level
    [ -d "$stagedir" ] || break
    echo ""
    echo "############  $(tstamp): Looking for jobs in $stagedir #############"
    while true ; do
	if [ -f "$ABORTFILE" ] ; then
	    echo "$(tstamp): ABORT signalled by another process; Exiting" >&2
	    exit $ABORT
	fi
	SLTM=$(bc -l <<< "scale=4 ; 4*${RANDOM}/32767 +2 ")
	echo "Sleeping for $SLTM (to avoid race condition)"
	sleep $SLTM

	#look for the next file
	set +e
	next_job=$(find $stagedir -name "*.job" 2> /dev/null | sed 1q)
	if [ -n "$next_job" ] ; then
	    #try to lock it 
	    if claim_job $next_job ; then
		#this file is ready to go
		echo "$(tstamp): Processing $next_job ..."
		lockfile=$(get_lockfilename $next_job)
		tmplog=$SCRATCHDIR/${stagedir}.$(basename $next_job .job).out
		tmperr=$SCRATCHDIR/${stagedir}.$(basename $next_job .job).err
		# If this is a DMC job, then load the pulses
		if [[ -n "$BATROOT_TEMPLATENAMES" ]] && [[ "$stage" -eq "2" ]]; then
		    dmc_input
		    echo "     Using Pulses from files: ${BATROOT_PULSELIBS}"
		fi
		#actually execute the job
		echo "$(tstamp): Worker $ID begin processing $next_job" >$tmplog
		./$lockfile >>$tmplog 2>$tmperr
		result=$?
		#put the logs into the permanent place
		[ -d $LOGDIR/$stagedir ] || $MKDIR $LOGDIR/$stagedir
		finalout=$LOGDIR/$stagedir/$(basename $next_job .job).out
		finalerr=$LOGDIR/$stagedir/$(basename $next_job .job).err
		mv -f $tmplog $finalout
		mv -f $tmperr $finalerr
		
		#check that the script succeeded
		case $result in 
		    $SUCCESS)
			echo "$(tstamp): Successfully processed job $next_job"
			/bin/mv $lockfile $(get_donefilename $next_job)
			;;
		    $ABORT)
			echo "$(tstamp): An ABORT  was generated by $next_job"
			echo "All processes will be aborted"
			echo "ID: $ID" >>$ABORTFILE
			echo "Job: $next_job" >>$ABORTFILE
			echo "Job content: $(cat $lockfile)" >>$ABORTFILE
			echo ""
			echo  "Error log:" >>$ABORTFILE
			cat $finalerr >>$ABORTFILE
			echo ""
			echo "Output log:" >>$ABORTFILE
			cat $finalout >>$ABORTFILE
			if [ -n "$EMAILADDY" ] ; then
			    $MAIL -s "auto_processing: ABORT in $(basename $WORKDIR)" $EMAILADDY <<-EOF
				$(tstamp): Worker ID $ID
				Working directory: $WORKDIR
				An ABORT error was generated by $next_job
				Error details:
				$(cat $ABORTFILE)
				All other workers will abort after their current job finishes.
				EOF
			fi
			exit $ABORT
			;;
		    $ABORTCALLED)
			echo "$(tstamp): ABORT called by another process"
			echo "Exiting now"
			exit $ABORTCALLED
			;;
		    *)
			echo "$(tstamp): $next_job failed with code $result"
			echo "Job will be marked as failed, but no ABORT"
			#see if we need to send an email
			if [ -n "$EMAILADDY" ] ; then
			    afailfile=$(find $stagedir -name "*.fail" 2>/dev/null | sed 1q)
			    if [ -z "$afailfile" ] ; then
				echo "Sending notification email"
		                #we are the first job to fail at this stage
				$MAIL -s "auto_processing: job failed in $(basename $WORKDIR)/$stagedir" $EMAILADDY <<-EOF
				$(tstamp): Worker ID $ID
				Working directory: $WORKDIR
				The following job in $stagedir has failed:
				$(get_failfilename $next_job)
				You will not be notified about any further failures in this stage.

				Job details: 
				$(cat $lockfile)

				Error log: 
				$(cat $finalerr)

				Output log:
				$(cat $finalout)
				EOF
			    fi
			fi
			
			/bin/mv -f $lockfile $(get_failfilename $next_job)
			;;
		esac
		#see if we're the last and need to send email
		if [ -n "$EMAILADDY" ] ; then
		    alockfile=$(find $stagedir -name "*.lock" -o -name "*.job" 2>/dev/null | sed 1q)
		    if [ -z "$alockfile" ] ; then
		        echo "Sending notification email"
		        #we are the last job in the stage
			failfiles=$(find $stagedir -name "*.fail" 2>/dev/null | wc -l )
			$MAIL -s "auto_processing: $(basename $WORKDIR)/$stagedir complete" $EMAILADDY <<-EOF
			$(tstamp): Worker ID $ID
			Working directory: $WORKDIR
			All jobs in $stagedir have finished processing 
			$failfiles jobs in this stage failed. 

			Overall jobstatus: (from jobstatus.py):
			$(./jobstatus.py .)
			EOF
		    fi
		fi
	    fi #end if successfully claimed job
	else
	    echo "No more files to process in $stagedir"
	    
	    break
	fi
	set +e
    done #end while true looking in given stage
done     #end loop over stages

#once here, there are no more scripts to process, so we can exit
echo "$(tstamp): processing_child with id $ID exiting"

exit $SUCCESS
